{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC Notes\n",
    "## Files\n",
    "### 20200303_ForestPotential_Samples.csv\n",
    "- system:index\n",
    "- CHELSA_Annual_Mean_Temperature\n",
    "- CHELSA_Annual_Precipitation\n",
    "- CHELSA_Mean_Temperature_of_Warmest_Quarter\n",
    "- CHELSA_Precipitation_Seasonality\n",
    "- CHELSA_Precipitation_of_Driest_Quarter\n",
    "- EarthEnvTopoMed_Eastness\n",
    "- EarthEnvTopoMed_Elevation\n",
    "- EarthEnvTopoMed_Northness\n",
    "- Lat\n",
    "- Long\n",
    "- Resolve_Biome\n",
    "- SG_Depth_to_bedrock\n",
    "- SG_Sand_Content_000cm\n",
    "- SG_Sand_Content_005cm\n",
    "- shrubcover\n",
    "- treecover\n",
    "- .geo\n",
    "\n",
    "### 20200303_ForestPotential_PointSampling\n",
    "No idea - Javascript file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for both Earth Engine work as well as map visualization within a Jupyter notebook\n",
    "import ee as ee\n",
    "ee.Initialize()\n",
    "import folium\n",
    "import geehydro #AC This isnt used anywhere\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### users/devinrouth/Resolve_Biomes_30ArcSec dataset\n",
    "Has 14 biomes:\n",
    "https://developers.google.com/earth-engine/datasets/catalog/RESOLVE_ECOREGIONS_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### users/devinrouth/Future_BioClim_Ensembles/rcp* datasets\n",
    "These are WorldClim data with added variables for ecology.  \n",
    "BIOCLIM variables https://www.edenextdata.com/?q=content/bioclim-worldclim-bioclimatic-variables-2000-20-50-80  \n",
    "The years are 2030,2050,2070,2080  \n",
    "The RCPS are 4.5 and 8.5  \n",
    "Have 19 variables:  \n",
    "Annual_Mean_Temperature: 29.585416666666667  \n",
    "Mean_Diurnal_Range: 9.506770833333333  \n",
    "Isothermality: 68.97395833333333  \n",
    "Temperature_Seasonality: 119.45416666666667  \n",
    "Max_Temperature_of_Warmest_Month: 37.36770833333333  \n",
    "Min_Temperature_of_Coldest_Month: 23.684375  \n",
    "Temperature_Annual_Range: 13.683333333333334  \n",
    "Mean_Temperature_of_Wettest_Quarter: 28.03333333333333  \n",
    "Mean_Temperature_of_Driest_Quarter: 30.833854166666665  \n",
    "Mean_Temperature_of_Warmest_Quarter: 31.144791666666666  \n",
    "Mean_Temperature_of_Coldest_Quarter: 27.9859375  \n",
    "Annual_Precipitation: 1932.15625  \n",
    "Precipitation_of_Wettest_Month: 277.9375  \n",
    "Precipitation_of_Driest_Month: 15.052083333333334  \n",
    "Precipitation_Seasonality: 58.651041666666664  \n",
    "Precipitation_of_Wettest_Quarter: 782.515625  \n",
    "Precipitation_of_Driest_Quarter: 77.85416666666667  \n",
    "Precipitation_of_Warmest_Quarter: 140.3125  \n",
    "Precipitation_of_Coldest_Quarter: 780.9010416666666  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"users/devinrouth/ETH_Composites/CrowtherLab_Composite_30ArcSec\" dataset\n",
    "This has 302 bands!! Including:  \n",
    "Aridity index  \n",
    "depth to water table  \n",
    "EVI  \n",
    "Cloud cover statistics  \n",
    "Texture measurements including Shannon and Simpson  \n",
    "Aspect, elevation, roughness, slope  \n",
    "FPAR  \n",
    "Above ground biomass  \n",
    "Hansen Forest cover  \n",
    "Human footprint  \n",
    "Landcover class  \n",
    "Mycorrhizae  \n",
    "NDVI ?  \n",
    "Nematodes  \n",
    "Lots of soil properties  \n",
    "Tree density  \n",
    "Chelsa Climate data http://chelsa-climate.org/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets of interest\n",
    "resolveBiomes = ee.Image(\"users/devinrouth/Resolve_Biomes_30ArcSec\")\n",
    "rcp45_2080s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp45_2080s_Mean\")\n",
    "rcp45_2030s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp45_2030s_Mean\")\n",
    "rcp45_2050s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp45_2050s_Mean\")\n",
    "rcp45_2070s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp45_2070s_Mean\")\n",
    "rcp85_2030s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp85_2030s_Mean\")\n",
    "rcp85_2050s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp85_2050s_Mean\")\n",
    "rcp85_2070s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp85_2070s_Mean\")\n",
    "rcp85_2080s_Mean = ee.Image(\"users/devinrouth/Future_BioClim_Ensembles/rcp85_2080s_Mean\")\n",
    "composite = ee.Image(\"users/devinrouth/ETH_Composites/CrowtherLab_Composite_30ArcSec\")\n",
    "\n",
    "# Create an unbounded geometry for later use\n",
    "# unboundedGeo = ee.Geometry.Rectangle([-180, -90, 180, 90], \"EPSG:4326\", False)\n",
    "unboundedGeo = ee.Geometry.Polygon([-180, 88, 0, 88, 180, 88, 180, -88, 0, -88, -180, -88], None, False);\n",
    "\n",
    "# !! Change testGeo when running full pipeline\n",
    "testGeo = ee.Geometry.Polygon(\n",
    "        [[[8.453552577781124, 47.44586460369053],\n",
    "          [8.453552577781124, 47.2896051444241],\n",
    "          [8.728210780906124, 47.2896051444241],\n",
    "          [8.728210780906124, 47.44586460369053]]], None, False);\n",
    "\n",
    "# Decide what geometry to use for exports (i.e., determining the extent of the maps)\n",
    "exportingGeometry = unboundedGeo\n",
    "\n",
    "# Create a list of biome number designations for later use\n",
    "biomeNumberList = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# Input the username folder where all of the images and collections will be saved\n",
    "# usernameFolderString = 'devinrouth_backup'\n",
    "usernameFolderString = 'acottam'\n",
    "\n",
    "# Input the name of the project folder wherein all (top-level) items will be saved\n",
    "# !! This folder must be created in order for the script to run\n",
    "projectFolder = 'ETH_Biome_Future_Predictions'\n",
    "\n",
    "# Input the name of the folder that will hold the bootstrapped samples\n",
    "bootstrapCollFolder = 'Bootstrap_Samples'\n",
    "\n",
    "# Select how many points per biome you'd like to sample\n",
    "pointsPerBiome = 2500\n",
    "\n",
    "# Select a tileScale to use across sampling calls\n",
    "# AC The default is 1 and this may be why it takes so long?\n",
    "tileScaleToUse = 16\n",
    "\n",
    "# Input the normal wait time (in seconds) for \"wait and break\" cells\n",
    "normalWaitTime = 60\n",
    "\n",
    "# Input the long wait time (in seconds) for \"wait and break\" cells\n",
    "longWaitTime = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write a list of random numbers to serve as the seed for the bootstrap collections; the number of seeds will determine the number of bootstraps\n",
    "# !! This list determines how many bootstrap samples will be created / modeled\n",
    "#seedList = list(range(1,1001))\n",
    "seedList = list(range(1,11))\n",
    "print(seedList)\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "# Choose how many collections/images to use/make at a time when bootstrapping\n",
    "n = 10\n",
    "seedChunkListToMap = [seedList[i:i + n] for i in range(0, len(seedList), n)]\n",
    "print(seedChunkListToMap)\n",
    "print('\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bash variables in order to create/check/delete Earth Engine Assets\n",
    "bashFunction = 'earthengine'\n",
    "arglist_CreateCollection = ['--no-use_cloud_api','create','collection']\n",
    "arglist_CreateFolder = ['--no-use_cloud_api','create','folder']\n",
    "arglist_Detect = ['--no-use_cloud_api','asset','info']\n",
    "arglist_Delete = ['--no-use_cloud_api','rm','-r']\n",
    "stringsOfInterest = ['Asset does not exist or is not accessible']\n",
    "bashCommandList_Detect = [bashFunction]+arglist_Detect\n",
    "bashCommandList_Delete = [bashFunction]+arglist_Delete\n",
    "bashCommandList_CreateCollection = [bashFunction]+arglist_CreateCollection\n",
    "bashCommandList_CreateFolder = [bashFunction]+arglist_CreateFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scaling image to ensure the scale of the CHELSA images matches the other images\n",
    "scalingDictionary = ee.Dictionary(\n",
    "{\n",
    "'CHELSA_Annual_Mean_Temperature':0.1,\n",
    "'CHELSA_Annual_Precipitation':1,\n",
    "'CHELSA_Isothermality':0.1,\n",
    "'CHELSA_Max_Temperature_of_Warmest_Month':0.1,\n",
    "'CHELSA_Mean_Diurnal_Range':0.1,\n",
    "'CHELSA_Mean_Temperature_of_Coldest_Quarter':0.1,\n",
    "'CHELSA_Mean_Temperature_of_Driest_Quarter':0.1,\n",
    "'CHELSA_Mean_Temperature_of_Warmest_Quarter':0.1,\n",
    "'CHELSA_Mean_Temperature_of_Wettest_Quarter':0.1,\n",
    "'CHELSA_Min_Temperature_of_Coldest_Month':0.1,\n",
    "'CHELSA_Precipitation_Seasonality':1,\n",
    "'CHELSA_Precipitation_of_Coldest_Quarter':1,\n",
    "'CHELSA_Precipitation_of_Driest_Month':1,\n",
    "'CHELSA_Precipitation_of_Driest_Quarter':1,\n",
    "'CHELSA_Precipitation_of_Warmest_Quarter':1,\n",
    "'CHELSA_Precipitation_of_Wettest_Month':1,\n",
    "'CHELSA_Precipitation_of_Wettest_Quarter':1,\n",
    "'CHELSA_Temperature_Annual_Range':0.1,\n",
    "'CHELSA_Temperature_Seasonality':0.1\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the CHELSA bands from the composite to match the future predictions on these bands\n",
    "# AC This is taking the above bands and multiplying their values by a constant image with the scale factors! Nice.\n",
    "chelsaMultibandImage = composite.select(scalingDictionary.keys()).multiply(scalingDictionary.toImage());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute lists of other variables to include in the models (i.e., soil and topographic variables)\n",
    "# AC topComp has the topographic variables: slope, elevation and aspect\n",
    "topComp = composite.select(['EarthEnvTopoMed_Slope','EarthEnvTopoMed_Elevation','EarthEnvTopoMed_Eastness','EarthEnvTopoMed_Northness']);\n",
    "# AC soilComp has the soil variables: organic carbon, pH, density, sand, water capacity, cation exchange capacity (CEC)\n",
    "soilComp = composite.select(['SG_CEC_000cm','SG_SOC_Density_000cm','SG_Soil_pH_H2O_000cm','SG_Bulk_density_000cm','SG_Sand_Content_000cm','SG_H2O_Capacity_000cm']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two images into a single variable\n",
    "totComp = chelsaMultibandImage.addBands(soilComp).addBands(topComp);\n",
    "# AC so the independent variables in the model are the following:\n",
    "# CHELSA climate, topographic and soil variables\n",
    "# These are used to train the Random Forest classifier\n",
    "covariateNames = totComp.bandNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make a dictionary to translate the band names\n",
    "# AC Between the CHELSA climate data dataset and the RCP scenario data (e.g. users/devinrouth/Future_BioClim_Ensembles/rcp45_2080s_Mean)\n",
    "chelsaDict =ee.Dictionary({\n",
    "'Annual_Mean_Temperature':'CHELSA_Annual_Mean_Temperature',\n",
    "'Mean_Diurnal_Range':'CHELSA_Mean_Diurnal_Range',\n",
    "'Isothermality':'CHELSA_Isothermality',\n",
    "'Temperature_Seasonality':'CHELSA_Temperature_Seasonality',\n",
    "'Max_Temperature_of_Warmest_Month':'CHELSA_Max_Temperature_of_Warmest_Month',\n",
    "'Min_Temperature_of_Coldest_Month':'CHELSA_Min_Temperature_of_Coldest_Month',\n",
    "'Temperature_Annual_Range':'CHELSA_Temperature_Annual_Range',\n",
    "'Mean_Temperature_of_Wettest_Quarter':'CHELSA_Mean_Temperature_of_Wettest_Quarter',\n",
    "'Mean_Temperature_of_Driest_Quarter':'CHELSA_Mean_Temperature_of_Driest_Quarter',\n",
    "'Mean_Temperature_of_Warmest_Quarter':'CHELSA_Mean_Temperature_of_Warmest_Quarter',\n",
    "'Mean_Temperature_of_Coldest_Quarter':'CHELSA_Mean_Temperature_of_Coldest_Quarter',\n",
    "'Annual_Precipitation':'CHELSA_Annual_Precipitation',\n",
    "'Precipitation_of_Wettest_Month':'CHELSA_Precipitation_of_Wettest_Month',\n",
    "'Precipitation_of_Driest_Month':'CHELSA_Precipitation_of_Driest_Month',\n",
    "'Precipitation_Seasonality':'CHELSA_Precipitation_Seasonality',\n",
    "'Precipitation_of_Wettest_Quarter':'CHELSA_Precipitation_of_Wettest_Quarter',\n",
    "'Precipitation_of_Driest_Quarter':'CHELSA_Precipitation_of_Driest_Quarter',\n",
    "'Precipitation_of_Warmest_Quarter':'CHELSA_Precipitation_of_Warmest_Quarter',\n",
    "'Precipitation_of_Coldest_Quarter':'CHELSA_Precipitation_of_Coldest_Quarter'\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all of the future imagery\n",
    "# AC This selects the climate fields in the Bioclim data and renames them\n",
    "rcp45_2030s_Mean = rcp45_2030s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "rcp45_2050s_Mean = rcp45_2050s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "rcp45_2070s_Mean = rcp45_2070s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "rcp45_2080s_Mean = rcp45_2080s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "\n",
    "rcp85_2030s_Mean = rcp85_2030s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "rcp85_2050s_Mean = rcp85_2050s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "rcp85_2070s_Mean = rcp85_2070s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "rcp85_2080s_Mean = rcp85_2080s_Mean.select(chelsaDict.keys(),chelsaDict.values());\n",
    "\n",
    "# AC This adds the soil and topographic variables to the Bioclim data\n",
    "rcp45_2030s_Mean_Soil = rcp45_2030s_Mean.addBands(soilComp).addBands(topComp);\n",
    "rcp45_2050s_Mean_Soil = rcp45_2050s_Mean.addBands(soilComp).addBands(topComp);\n",
    "rcp45_2070s_Mean_Soil = rcp45_2070s_Mean.addBands(soilComp).addBands(topComp);\n",
    "rcp45_2080s_Mean_Soil = rcp45_2080s_Mean.addBands(soilComp).addBands(topComp);\n",
    "\n",
    "rcp85_2030s_Mean_Soil = rcp85_2030s_Mean.addBands(soilComp).addBands(topComp);\n",
    "rcp85_2050s_Mean_Soil = rcp85_2050s_Mean.addBands(soilComp).addBands(topComp);\n",
    "rcp85_2070s_Mean_Soil = rcp85_2070s_Mean.addBands(soilComp).addBands(topComp);\n",
    "rcp85_2080s_Mean_Soil = rcp85_2080s_Mean.addBands(soilComp).addBands(topComp);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the training and test samples\n",
    "trainSamplesToExport = totComp.addBands(resolveBiomes.rename('ResolveBiome').int()).stratifiedSample(\n",
    "    numPoints=pointsPerBiome,\n",
    "    classBand='ResolveBiome',\n",
    "    region=unboundedGeo,\n",
    "    seed=11111,\n",
    "    tileScale=tileScaleToUse,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "validateSamplesToExport = totComp.addBands(resolveBiomes.rename('ResolveBiome').int()).stratifiedSample(\n",
    "    numPoints=pointsPerBiome,\n",
    "    classBand='ResolveBiome',\n",
    "    region=unboundedGeo,\n",
    "    seed=22222,\n",
    "    tileScale=tileScaleToUse,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "testSamplesToExport = totComp.addBands(resolveBiomes.rename('ResolveBiome').int()).stratifiedSample(\n",
    "    numPoints=pointsPerBiome,\n",
    "    classBand='ResolveBiome',\n",
    "    region=unboundedGeo,\n",
    "    seed=33333,\n",
    "    tileScale=tileScaleToUse,\n",
    "    geometries=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the export then wait for it to finish before moving on\n",
    "trainingSampleExport = ee.batch.Export.table.toAsset(\n",
    "    collection=trainSamplesToExport,\n",
    "    description='trainingSamples',\n",
    "    assetId='users/'+usernameFolderString+'/'+projectFolder+'/trainingSamples'\n",
    ");\n",
    "trainingSampleExport.start()\n",
    "\n",
    "validateSampleExport = ee.batch.Export.table.toAsset(\n",
    "    collection=validateSamplesToExport,\n",
    "    description='validateSamples',\n",
    "    assetId='users/'+usernameFolderString+'/'+projectFolder+'/validateSamples'\n",
    ");\n",
    "validateSampleExport.start()\n",
    "\n",
    "testSampleExport = ee.batch.Export.table.toAsset(\n",
    "    collection=testSamplesToExport,\n",
    "    description='testSamples',\n",
    "    assetId='users/'+usernameFolderString+'/'+projectFolder+'/testSamples'\n",
    ");\n",
    "testSampleExport.start()\n",
    "\n",
    "# Sleep to ensure the jobs have been queued\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the collections\n",
    "trainSamples = ee.FeatureCollection('users/'+usernameFolderString+'/'+projectFolder+'/trainingSamples')\n",
    "validateSamples = ee.FeatureCollection('users/'+usernameFolderString+'/'+projectFolder+'/validateSamples')\n",
    "testSamples = ee.FeatureCollection('users/'+usernameFolderString+'/'+projectFolder+'/testSamples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a selection of random forest classifiers to determine the best model (using features for wrapping, so the entire process can be processed via an export task)\n",
    "rf_VP2 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP2','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=2,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP3 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP3','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=3,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP4 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP4','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=4,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP5 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP5','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=5,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP6 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP6','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=6,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP7 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP7','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=7,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP8 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP8','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=8,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP9 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP9','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=9,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP10 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP10','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=10,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP12 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP12','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=12,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n",
    "rf_VP14 = ee.Feature(ee.Geometry.Point([0,0])).set('cName','rf_VP14','c',ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=14,\n",
    "    bagFraction=0.632\n",
    ").setOutputMode('CLASSIFICATION').train(trainSamples,'ResolveBiome',covariateNames))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map through the trained classifiers, classify the validation samples, then compute their accuracy to compare them\n",
    "classifierFC = ee.FeatureCollection([rf_VP2,\n",
    "                                     rf_VP3,\n",
    "                                     rf_VP4,\n",
    "                                     rf_VP5,\n",
    "                                     rf_VP6,\n",
    "                                     rf_VP7,\n",
    "                                     rf_VP8,\n",
    "                                     rf_VP9,\n",
    "                                     rf_VP10,\n",
    "                                     rf_VP12,\n",
    "                                     rf_VP14])\n",
    "\n",
    "def outputValidationAccuracy(classiferFeature):\n",
    "    return ee.Feature(classiferFeature).set('OverallAccuracy',validateSamples.classify(ee.Feature(classiferFeature).get('c'),'PredictedBiome').errorMatrix('ResolveBiome','PredictedBiome').accuracy()).select(['OverallAccuracy','cName'])\n",
    "\n",
    "# !! Export the accuracy FC\n",
    "accuracyFC = classifierFC.map(outputValidationAccuracy).sort('OverallAccuracy',False)\n",
    "\n",
    "finalClassifierFCExport = ee.batch.Export.table.toAsset(\n",
    "    collection=ee.FeatureCollection(accuracyFC),\n",
    "    description='finalClassifierFC',\n",
    "    assetId='users/'+usernameFolderString+'/'+projectFolder+'/finalClassifierFC'\n",
    ");\n",
    "finalClassifierFCExport.start()\n",
    "\n",
    "# Sleep to ensure the job has been queued\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Export the best model information separately\n",
    "bestModelDictionary = ee.Feature(accuracyFC.first()).toDictionary()\n",
    "finalValidationFCExport = ee.batch.Export.table.toAsset(\n",
    "    collection=ee.FeatureCollection(ee.Feature(ee.Geometry.Point([0,0])).set(bestModelDictionary)),\n",
    "    description='finalValidationFC',\n",
    "    assetId='users/'+usernameFolderString+'/'+projectFolder+'/finalValidationFC'\n",
    ");\n",
    "finalValidationFCExport.start()\n",
    "\n",
    "# Sleep to ensure the job has been queued\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the final accuracy on the test collection\n",
    "bestModelName = ee.Feature(ee.FeatureCollection('users/'+usernameFolderString+'/'+projectFolder+'/finalValidationFC').first()).get('cName')\n",
    "bestModel = ee.Feature(classifierFC.filterMetadata('cName','equals',bestModelName).first()).get('c')\n",
    "finalAccuracy = testSamples.classify(ee.Classifier(bestModel),'PredictedBiome').errorMatrix('ResolveBiome','PredictedBiome',biomeNumberList).accuracy()\n",
    "kappaAccuracy = testSamples.classify(ee.Classifier(bestModel),'PredictedBiome').errorMatrix('ResolveBiome','PredictedBiome',biomeNumberList).kappa()\n",
    "\n",
    "# !! Export the final accuracy\n",
    "finalAccuracyFCExport = ee.batch.Export.table.toAsset(\n",
    "    collection=ee.FeatureCollection(ee.Feature(ee.Geometry.Point([0,0])).set('FinalAccuracy',finalAccuracy).set('KappaAccuracy',kappaAccuracy)),\n",
    "    description='finalAccuracyFC',\n",
    "    assetId='users/'+usernameFolderString+'/'+projectFolder+'/finalAccuracyFC'\n",
    ");\n",
    "finalAccuracyFCExport.start()\n",
    "\n",
    "# Sleep to ensure the job has been queued\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalAccuracy\n",
      "0.8940857142857143 \n",
      "\n",
      "KappaAccuracy\n",
      "0.8859384615384616 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return accuracy values here\n",
    "finalAccuracyToPrint = ee.Feature(ee.FeatureCollection('users/'+usernameFolderString+'/'+projectFolder+'/finalAccuracyFC').first()).get('FinalAccuracy')\n",
    "print('FinalAccuracy');\n",
    "print(finalAccuracyToPrint.getInfo(),'\\n')\n",
    "\n",
    "kappaAccuracyToPrint = ee.Feature(ee.FeatureCollection('users/'+usernameFolderString+'/'+projectFolder+'/finalAccuracyFC').first()).get('KappaAccuracy')\n",
    "print('KappaAccuracy');\n",
    "print(kappaAccuracyToPrint.getInfo(),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2008, 163, 45, 17, 6, 0, 97, 0, 3, 15, 0, 0, 1, 145], [73, 2151, 111, 0, 0, 0, 37, 0, 31, 15, 0, 0, 7, 75], [33, 31, 2395, 2, 7, 0, 1, 0, 0, 4, 0, 0, 1, 26], [13, 0, 8, 2149, 112, 35, 6, 55, 33, 21, 0, 54, 12, 2], [5, 0, 6, 62, 2138, 27, 0, 49, 1, 128, 7, 40, 37, 0], [0, 0, 0, 42, 56, 2233, 0, 25, 1, 0, 143, 0, 0, 0], [75, 69, 7, 4, 0, 0, 2219, 13, 59, 10, 0, 1, 33, 10], [0, 0, 0, 82, 70, 30, 3, 2205, 16, 18, 0, 39, 36, 1], [5, 13, 1, 6, 0, 0, 80, 5, 2350, 0, 0, 3, 28, 9], [17, 1, 16, 19, 125, 0, 33, 30, 0, 2191, 0, 6, 62, 0], [0, 0, 0, 6, 11, 192, 0, 0, 0, 2, 2289, 0, 0, 0], [0, 0, 0, 22, 31, 0, 0, 6, 2, 9, 0, 2396, 34, 0], [2, 50, 32, 2, 22, 0, 36, 56, 19, 54, 0, 42, 2174, 11], [59, 24, 11, 0, 0, 0, 2, 0, 5, 0, 0, 0, 4, 2395]]\n",
      "\n",
      "\n",
      "2008 163 45 17 6 0 97 0 3 15 0 0 1 145\n",
      "73 2151 111 0 0 0 37 0 31 15 0 0 7 75\n",
      "33 31 2395 2 7 0 1 0 0 4 0 0 1 26\n",
      "13 0 8 2149 112 35 6 55 33 21 0 54 12 2\n",
      "5 0 6 62 2138 27 0 49 1 128 7 40 37 0\n",
      "0 0 0 42 56 2233 0 25 1 0 143 0 0 0\n",
      "75 69 7 4 0 0 2219 13 59 10 0 1 33 10\n",
      "0 0 0 82 70 30 3 2205 16 18 0 39 36 1\n",
      "5 13 1 6 0 0 80 5 2350 0 0 3 28 9\n",
      "17 1 16 19 125 0 33 30 0 2191 0 6 62 0\n",
      "0 0 0 6 11 192 0 0 0 2 2289 0 0 0\n",
      "0 0 0 22 31 0 0 6 2 9 0 2396 34 0\n",
      "2 50 32 2 22 0 36 56 19 54 0 42 2174 11\n",
      "59 24 11 0 0 0 2 0 5 0 0 0 4 2395\n"
     ]
    }
   ],
   "source": [
    "# Show the raw confusion matrix for the test data\n",
    "# !! Use a while loop here to repeat the code in case there are Computation time out errors\n",
    "while True:\n",
    "    try:\n",
    "        confusionMatrix = testSamples.classify(ee.Classifier(bestModel),'PredictedBiome').errorMatrix('ResolveBiome','PredictedBiome',biomeNumberList).array().getInfo()\n",
    "        print(confusionMatrix)\n",
    "        print('\\n')\n",
    "    except Exception as e:\n",
    "        print(e,' : ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        time.sleep(30)\n",
    "        continue\n",
    "    else:\n",
    "         break\n",
    "\n",
    "for r in confusionMatrix:\n",
    "    print(*r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8768558951965065, 0.8597122302158273, 0.9099544072948328, 0.8905926232905097, 0.8293250581846393, 0.8871672626142233, 0.8826571201272871, 0.9022094926350246, 0.9325396825396826, 0.8881232265910012, 0.9384993849938499, 0.9283223556760946, 0.8950185261424455, 0.8956619296933434]\n",
      "\n",
      "\n",
      "Biome  1 :  0.8768558951965065\n",
      "Biome  2 :  0.8597122302158273\n",
      "Biome  3 :  0.9099544072948328\n",
      "Biome  4 :  0.8905926232905097\n",
      "Biome  5 :  0.8293250581846393\n",
      "Biome  6 :  0.8871672626142233\n",
      "Biome  7 :  0.8826571201272871\n",
      "Biome  8 :  0.9022094926350246\n",
      "Biome  9 :  0.9325396825396826\n",
      "Biome  10 :  0.8881232265910012\n",
      "Biome  11 :  0.9384993849938499\n",
      "Biome  12 :  0.9283223556760946\n",
      "Biome  13 :  0.8950185261424455\n",
      "Biome  14 :  0.8956619296933434\n"
     ]
    }
   ],
   "source": [
    "# Show the consumers' accuracy for the test data\n",
    "# !! Use a while loop here to repeat the code in case there are Computation time out errors\n",
    "while True:\n",
    "    try:\n",
    "        consumersMatrix = testSamples.classify(ee.Classifier(bestModel),'PredictedBiome').errorMatrix('ResolveBiome','PredictedBiome',biomeNumberList).consumersAccuracy().getInfo()[0]\n",
    "        print(consumersMatrix)\n",
    "        print('\\n')\n",
    "    except Exception as e:\n",
    "        print(e,' : ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        time.sleep(30)\n",
    "        continue\n",
    "    else:\n",
    "         break\n",
    "\n",
    "for b in biomeNumberList:\n",
    "    print('Biome ',b,': ',consumersMatrix[b-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8032], [0.8604], [0.958], [0.8596], [0.8552], [0.8932], [0.8876], [0.882], [0.94], [0.8764], [0.9156], [0.9584], [0.8696], [0.958]]\n",
      "\n",
      "\n",
      "Biome  1 :  0.8032\n",
      "Biome  2 :  0.8604\n",
      "Biome  3 :  0.958\n",
      "Biome  4 :  0.8596\n",
      "Biome  5 :  0.8552\n",
      "Biome  6 :  0.8932\n",
      "Biome  7 :  0.8876\n",
      "Biome  8 :  0.882\n",
      "Biome  9 :  0.94\n",
      "Biome  10 :  0.8764\n",
      "Biome  11 :  0.9156\n",
      "Biome  12 :  0.9584\n",
      "Biome  13 :  0.8696\n",
      "Biome  14 :  0.958\n"
     ]
    }
   ],
   "source": [
    "# Print the producers' accuracy values\n",
    "# !! Use a while loop here to repeat the code in case there are Computation time out errors\n",
    "while True:\n",
    "    try:\n",
    "        producersMatrix = testSamples.classify(ee.Classifier(bestModel),'PredictedBiome').errorMatrix('ResolveBiome','PredictedBiome',biomeNumberList).producersAccuracy().getInfo()\n",
    "        print(producersMatrix)\n",
    "        print('\\n')\n",
    "    except Exception as e:\n",
    "        print(e,' : ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        time.sleep(30)\n",
    "        continue\n",
    "    else:\n",
    "         break\n",
    "\n",
    "for b in biomeNumberList:\n",
    "    print('Biome ',b,': ',producersMatrix[b-1][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users/acottam/ETH_Biome_Future_Predictions/Bootstrap_Samples being created...\n",
      "Asset created!\n"
     ]
    }
   ],
   "source": [
    "# Create a folder to house the bootstrapped feature collection\n",
    "\n",
    "# Turn the folder string into an assetID and perform the deletion\n",
    "assetIDToCreate_Folder = 'users/'+usernameFolderString+'/'+projectFolder+'/'+bootstrapCollFolder\n",
    "print(assetIDToCreate_Folder,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateFolder+[assetIDToCreate_Folder])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate_Folder], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function load each of the collections in, chunk by chunk, and use them to predict a composite\n",
    "# Create the bootstrap collections for training\n",
    "for seed in seedList:\n",
    "    assetIDString = str('BootstrapSamples_')+str(seed).zfill(4)\n",
    "    bootstrapSamples = totComp.addBands(resolveBiomes.rename('ResolveBiome').int()).stratifiedSample(\n",
    "    numPoints=pointsPerBiome,\n",
    "    classBand='ResolveBiome',\n",
    "    region=unboundedGeo,\n",
    "    seed=seed,\n",
    "    tileScale=tileScaleToUse,\n",
    "    geometries=True\n",
    "    )\n",
    "    \n",
    "    bootstrapSampleExport = ee.batch.Export.table.toAsset(\n",
    "        collection=bootstrapSamples,\n",
    "        description=assetIDString,\n",
    "        assetId='users/'+usernameFolderString+'/'+projectFolder+'/'+bootstrapCollFolder+'/'+assetIDString\n",
    "    );\n",
    "    bootstrapSampleExport.start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have jobs running!  2020-04-05 11:36:47\n",
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical image to a multi-band indicator variable style image\n",
    "# AC This is the WWF Global 200 - https://en.wikipedia.org/wiki/Global_200\n",
    "resolveBiomesDict = {\n",
    "1: 'Tropical and subtropical moist broadleaf forests',\n",
    "2: 'Tropical and subtropical dry broadleaf forests',\n",
    "3: 'Tropical and subtropical coniferous forests',\n",
    "4: 'Temperate broadleaf and mixed forests',\n",
    "5: 'Temperate conifer forests',\n",
    "6: 'Boreal forests or taiga',\n",
    "7: 'Tropical and subtropical grasslands, savannas, and shrublands',\n",
    "8: 'Temperate grasslands, savannas, and shrublands',\n",
    "9: 'Flooded Grasslands and Savannas',\n",
    "10: 'Montane grasslands and shrublands',\n",
    "11: 'Tundra',\n",
    "12: 'Mediterranean forests, woodlands, and scrub',\n",
    "13: 'Deserts and xeric shrublands',\n",
    "14: 'Mangroves'\n",
    "};\n",
    "\n",
    "# Instantiate each of the desired function arguments before the scope of the function so as to have only a single argument to the function\n",
    "classBandToMap = 'Resolve_Biome';\n",
    "classDictToMap = resolveBiomesDict;\n",
    "imageNameForBands = 'ResolveBiome';\n",
    "def categoricalToIndicatorWithoutRefToApply(inputCatImage):\n",
    "    def makeBooleanRasterFromValue(i):\n",
    "        return ee.Image(inputCatImage).select(classBandToMap).eq(ee.Image(ee.Number.parse(i))).rename(ee.String(imageNameForBands).cat(ee.String('_')).cat(ee.Number.parse(i).format('%02d')));\n",
    "    # AC Make a boolean image for each biome and add it to an image list\n",
    "    catClassImageList = ee.Dictionary(classDictToMap).keys().map(makeBooleanRasterFromValue);\n",
    "    def makeRasterFromImageList(i,b):\n",
    "        return ee.Image(b).addBands(i)\n",
    "    #AC Converts the image list to a single image with bands ResolveBiome_01, ResolveBiome_02 etc\n",
    "    unsortedBandImage = ee.Image(catClassImageList.iterate(makeRasterFromImageList,ee.Image()))\n",
    "    return unsortedBandImage.select(unsortedBandImage.bandNames().remove('constant').sort());\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make the bootstrap indicator images and save them to a recipient image collection\n",
    "def makeBootstrapIC(imageToClassify,parentColl,listOfLists):\n",
    "\n",
    "    for seeds in listOfLists:\n",
    "        seedChunkList = seeds\n",
    "        indexString = str(listOfLists.index(seeds)).zfill(2)\n",
    "\n",
    "        fcAssetIDList = []\n",
    "        for seed in seedChunkList:\n",
    "            assetIDString = str('BootstrapSamples_')+str(seed).zfill(4)\n",
    "            # AC load the bootstrap training samples\n",
    "            assetId='users/'+usernameFolderString+'/'+projectFolder+'/'+bootstrapCollFolder+'/'+assetIDString\n",
    "            fcAssetIDList.append(assetId)\n",
    "            def returnFCFromString(string):\n",
    "                return ee.FeatureCollection(string)\n",
    "            # AC creates an image collection with the image to classify with a property for the bootstrap samples\n",
    "            imageCollWithTrainingColls = ee.ImageCollection(ee.List(list(map(returnFCFromString,fcAssetIDList)))\n",
    "                                                            .map(lambda s: imageToClassify.set('TrainingCollection',ee.FeatureCollection(s),\n",
    "                                                                                               'TrainingString',s)))\n",
    "        def classifyImage(imageWithColl):\n",
    "            trainingCollToUse = ee.FeatureCollection(imageWithColl.get('TrainingCollection'))\n",
    "            trainedModel = ee.Classifier(bestModel).setOutputMode('CLASSIFICATION').train(trainingCollToUse,'ResolveBiome',covariateNames)\n",
    "            classifiedImage = imageWithColl.classify(trainedModel,'PredictedBiome').rename('Resolve_Biome')\n",
    "            return categoricalToIndicatorWithoutRefToApply(classifiedImage.copyProperties(imageWithColl,['TrainingString']))\n",
    "\n",
    "\n",
    "        classifiedImageCollSum = ee.ImageCollection(imageCollWithTrainingColls.map(classifyImage)).sum()\n",
    "        ImageExport = ee.batch.Export.image.toAsset(\n",
    "            image=classifiedImageCollSum,\n",
    "            description=parentColl+'_'+'BootstrapImage_'+indexString,\n",
    "            assetId='users/'+usernameFolderString+'/'+projectFolder+'/'+parentColl+'/BootstrapImage_'+indexString,\n",
    "            crs='EPSG:4326',\n",
    "            crsTransform='[0.008333333333333333,0,-180,0,-0.008333333333333333,90]',\n",
    "            region=exportingGeometry.getInfo()['coordinates'],\n",
    "            maxPixels=int(1e13)\n",
    "        );\n",
    "        ImageExport.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap each of the time periods, sum the collection, then delete the image collection (to make room in the account asset storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usernameFolderString = 'devinrouth_backup'\n",
    "usernameFolderString = 'acottam'\n",
    "projectFolder = 'ETH_Biome_Future_Predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bash variables in order to create/check/delete Earth Engine Assets\n",
    "bashFunction = 'earthengine'\n",
    "arglist_CreateCollection = ['--no-use_cloud_api','create','collection']\n",
    "arglist_CreateFolder = ['--no-use_cloud_api','create','folder']\n",
    "arglist_Detect = ['--no-use_cloud_api','asset','info']\n",
    "arglist_Delete = ['--no-use_cloud_api','rm','-r']\n",
    "stringsOfInterest = ['Asset does not exist or is not accessible']\n",
    "bashCommandList_Detect = [bashFunction]+arglist_Detect\n",
    "bashCommandList_Delete = [bashFunction]+arglist_Delete\n",
    "bashCommandList_CreateCollection = [bashFunction]+arglist_CreateCollection\n",
    "bashCommandList_CreateFolder = [bashFunction]+arglist_CreateFolder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp45_2030s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users/acottam/ETH_Biome_Future_Predictions/rcp45_2030s_Coll being created...\n",
      "Asset created!\n"
     ]
    }
   ],
   "source": [
    "# rcp45_2030s Image Collection creation\n",
    "rcp45_2030s_Coll = 'rcp45_2030s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp45_2030s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bootstrap images inside of the collection\n",
    "# AC params to makeBootstrapIC are: image to classify, parent collection, list of lists\n",
    "rcp45_2030s_Classified = makeBootstrapIC(rcp45_2030s_Mean_Soil,rcp45_2030s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have jobs running!  2020-04-05 11:48:00\n",
      "You have jobs running!  2020-04-05 11:58:01\n",
      "You have jobs running!  2020-04-05 12:08:02\n",
      "You have jobs running!  2020-04-05 12:18:03\n",
      "You have jobs running!  2020-04-05 12:28:04\n",
      "You have jobs running!  2020-04-05 12:38:05\n",
      "You have jobs running!  2020-04-05 12:48:06\n",
      "You have jobs running!  2020-04-05 12:58:07\n",
      "You have jobs running!  2020-04-05 13:08:09\n",
      "You have jobs running!  2020-04-05 13:18:10\n",
      "You have jobs running!  2020-04-05 13:28:11\n",
      "You have jobs running!  2020-04-05 13:38:12\n",
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to load in an image collection (by asset string name) then sum it an export the resultant image\n",
    "def sumImageCollection(collStringName):\n",
    "    pathOfImageCollToSum = 'users/'+usernameFolderString+'/'+projectFolder+'/'+collStringName;\n",
    "    outputPathOfSummedImage = 'users/'+usernameFolderString+'/'+projectFolder+'/'+collStringName+'_SummedImage';\n",
    "    summedImageToExport = ee.ImageCollection(pathOfImageCollToSum).sum()\n",
    "    \n",
    "    summedImageExportTask = ee.batch.Export.image.toAsset(\n",
    "        image=summedImageToExport,\n",
    "        description=collStringName+'_SummedImage',\n",
    "        assetId=outputPathOfSummedImage,\n",
    "        crs='EPSG:4326',\n",
    "        crsTransform='[0.008333333333333333,0,-180,0,-0.008333333333333333,90]',\n",
    "        region=exportingGeometry.getInfo()['coordinates'],\n",
    "        maxPixels=int(1e13)\n",
    "    );\n",
    "    summedImageExportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp45_2030s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have jobs running!  2020-04-05 13:48:16\n",
      "You have jobs running!  2020-04-05 13:49:17\n",
      "You have jobs running!  2020-04-05 13:50:17\n",
      "You have jobs running!  2020-04-05 13:51:18\n",
      "You have jobs running!  2020-04-05 13:52:19\n",
      "You have jobs running!  2020-04-05 13:53:19\n",
      "You have jobs running!  2020-04-05 13:54:19\n",
      "You have jobs running!  2020-04-05 13:55:20\n",
      "You have jobs running!  2020-04-05 13:56:20\n",
      "You have jobs running!  2020-04-05 13:57:21\n",
      "You have jobs running!  2020-04-05 13:58:21\n",
      "You have jobs running!  2020-04-05 13:59:22\n",
      "You have jobs running!  2020-04-05 14:00:23\n",
      "You have jobs running!  2020-04-05 14:01:23\n",
      "You have jobs running!  2020-04-05 14:02:23\n",
      "You have jobs running!  2020-04-05 14:03:24\n",
      "You have jobs running!  2020-04-05 14:04:24\n",
      "You have jobs running!  2020-04-05 14:05:25\n",
      "You have jobs running!  2020-04-05 14:06:25\n",
      "You have jobs running!  2020-04-05 14:07:26\n",
      "You have jobs running!  2020-04-05 14:08:26\n",
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "# Wait while all queued tasks finish\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users/acottam/ETH_Biome_Future_Predictions/rcp45_2030s_Coll being deleted\n",
      "Collection is deleted!\n"
     ]
    }
   ],
   "source": [
    "# rcp45_2030s_Coll\n",
    "currentCollToDelete = rcp45_2030s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp45_2050s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users/acottam/ETH_Biome_Future_Predictions/rcp45_2050s_Coll being created...\n",
      "Asset created!\n"
     ]
    }
   ],
   "source": [
    "# rcp45_2050s Image Collection creation\n",
    "rcp45_2050s_Coll = 'rcp45_2050s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp45_2050s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bootstrap images inside of the collection\n",
    "rcp45_2050s_Classified = makeBootstrapIC(rcp45_2050s_Mean_Soil,rcp45_2050s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have jobs running!  2020-04-05 14:10:49\n",
      "You have jobs running!  2020-04-05 14:20:50\n"
     ]
    }
   ],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp45_2050s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp45_2050s_Coll\n",
    "currentCollToDelete = rcp45_2050s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp45_2070s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp45_2070s_Coll Image Collection creation\n",
    "rcp45_2070s_Coll = 'rcp45_2070s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp45_2070s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bootstrap images inside of the collection\n",
    "rcp45_2070s_Classified = makeBootstrapIC(rcp45_2070s_Mean_Soil,rcp45_2070s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp45_2070s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp45_2070s_Coll\n",
    "currentCollToDelete = rcp45_2070s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp45_2080s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp45_2080s_Coll Image Collection creation\n",
    "rcp45_2080s_Coll = 'rcp45_2080s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp45_2080s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bootstrap images inside of the collection\n",
    "rcp45_2080s_Classified = makeBootstrapIC(rcp45_2080s_Mean_Soil,rcp45_2080s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp45_2080s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp45_2080s_Coll\n",
    "currentCollToDelete = rcp45_2080s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp85_2030s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2030s_Coll Image Collection creation\n",
    "rcp85_2030s_Coll = 'rcp85_2030s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp85_2030s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bootstrap images inside of the collection\n",
    "rcp85_2030s_Classified = makeBootstrapIC(rcp85_2030s_Mean_Soil,rcp85_2030s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp85_2030s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2030s_Coll\n",
    "currentCollToDelete = rcp85_2030s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp85_2050s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2050s_Coll Image Collection creation\n",
    "rcp85_2050s_Coll = 'rcp85_2050s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp85_2050s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bootstrap images inside of the collection\n",
    "rcp85_2050s_Classified = makeBootstrapIC(rcp85_2050s_Mean_Soil,rcp85_2050s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "# Wait while all queued tasks finish\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp85_2050s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "# Wait while all queued tasks finish\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2050s_Coll\n",
    "currentCollToDelete = rcp85_2050s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp85_2070s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2070s_Coll Image Collection creation\n",
    "rcp85_2070s_Coll = 'rcp85_2070s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp85_2070s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the coll string into an assetID and perform the deletion\n",
    "rcp85_2070s_Classified = makeBootstrapIC(rcp85_2070s_Mean_Soil,rcp85_2070s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp85_2070s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "# Wait while all queued tasks finish\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2070s_Coll\n",
    "currentCollToDelete = rcp85_2070s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rcp85_2080s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2080s_Coll Image Collection creation\n",
    "rcp85_2080s_Coll = 'rcp85_2080s_Coll';\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "currentCollToCreate = rcp85_2080s_Coll\n",
    "assetIDToCreate = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToCreate\n",
    "print(assetIDToCreate,'being created...')\n",
    "\n",
    "# Create the image collection before classifying each of the bootstrap images\n",
    "subprocess.run(bashCommandList_CreateCollection+[assetIDToCreate])\n",
    "while any(x in subprocess.run(bashCommandList_Detect+[assetIDToCreate], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for asset to be created...')\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Asset created!')\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the image collection before classifying each of the bootstrap images\n",
    "rcp85_2080s_Classified = makeBootstrapIC(rcp85_2080s_Mean_Soil,rcp85_2080s_Coll,seedChunkListToMap);\n",
    "\n",
    "# Sleep to allow the server time to receive incoming requests\n",
    "time.sleep(normalWaitTime/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(longWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each of the image collections to get a finalized map\n",
    "sumImageCollection(rcp85_2080s_Coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Break and wait\n",
    "while any(x in str(ee.batch.Task.list()) for x in ['RUNNING','READY']):\n",
    "    print('You have jobs running! ',datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time.sleep(normalWaitTime)\n",
    "print('Moving on...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcp85_2080s_Coll\n",
    "currentCollToDelete = rcp85_2080s_Coll\n",
    "\n",
    "# Turn the coll string into an assetID and perform the deletion\n",
    "assetIDToDelete = 'users/'+usernameFolderString+'/'+projectFolder+'/'+currentCollToDelete\n",
    "print(assetIDToDelete,'being deleted')\n",
    "\n",
    "# Delete the image collection after summing the \n",
    "subprocess.run(bashCommandList_Delete+[assetIDToDelete])\n",
    "while not all(x in subprocess.run(bashCommandList_Detect+[assetIDToDelete], stdout=subprocess.PIPE).stdout.decode('utf-8') for x in stringsOfInterest):\n",
    "    print('Waiting for the asset to delete...')\n",
    "    time.sleep(5)\n",
    "print('Collection is deleted!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
